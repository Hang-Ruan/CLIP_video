{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7_pus27iP6n",
        "outputId": "35e814d9-9f6b-4957-832e-576933fd6f28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Apr 24 00:40:09 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla V100-SXM2-32GB           On  |   00000000:3B:00.0 Off |                    0 |\n",
            "| N/A   30C    P0             41W /  300W |       1MiB /  32768MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # You’ll have to clone **YOUR OWN BRANCH**: \"!git clone -b [your_branch_name] https://github.com/sijiasiga/CLIP_video.git\" \n",
        "# # or **MIAIN BRANCH** (initial version) by using \"!git clone https://github.com/sijiasiga/CLIP_video.git\" \n",
        "# !git clone https://github.com/sijiasiga/CLIP_video.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGfdhKIXipJr",
        "outputId": "e6795d6c-5769-4687-8c3f-a3d9ea316405"
      },
      "outputs": [],
      "source": [
        "# From CLIP\n",
        "# !conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0\n",
        "# !pip install ftfy regex tqdm\n",
        "# !pip install opencv-python boto3 requests pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Download Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download MSRVTT training data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WAT-NYLMm22_"
      },
      "outputs": [],
      "source": [
        "# # Comment if the file exits\n",
        "# !wget -O /ocean/projects/cis250079p/shared/data/msrvtt_data.zip https://github.com/ArrowLuo/CLIP4Clip/releases/download/v0.0/msrvtt_data.zip\n",
        "# !unzip /ocean/projects/cis250079p/shared/data/msrvtt_data.zip -d /ocean/projects/cis250079p/shared/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download MSRVTT raw video dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !wget -O /ocean/projects/cis250079p/shared/data/msrvtt_raw_video_data.zip https://www.robots.ox.ac.uk/~maxbain/frozen-in-time/data/msrvtt_raw_video_data.zip\n",
        "# !unzip /ocean/projects/cis250079p/shared/data/msrvtt_raw_video_data.zip -d /ocean/projects/cis250079p/shared/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MSRVTT Data Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uYqhvAKVpQD9"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/ocean/projects/cis250079p/shared/data/msrvtt_data\"  # Directory of MSRVTT data\n",
        "VIDEO_PATH = \"/ocean/projects/cis250079p/shared/data/msrvtt_raw_video_data/videos/all/\"    # Directory of MSRVTT raw video data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Split the subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "3U2GCKmL14G6",
        "outputId": "d6116cab-8d51-4001-c050-9b300ed4d5d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size:  9000\n",
            "Column names ['video_id']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>video0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>video1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>video2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>video3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>video4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  video_id\n",
              "0   video0\n",
              "1   video1\n",
              "2   video2\n",
              "3   video3\n",
              "4   video4"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of subset： 900\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>video8405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>video1162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>video582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>video4081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>video9139</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    video_id\n",
              "0  video8405\n",
              "1  video1162\n",
              "2   video582\n",
              "3  video4081\n",
              "4  video9139"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load training dataset\n",
        "train_path = f\"{DATA_PATH}/MSRVTT_train.9k.csv\"\n",
        "df = pd.read_csv(train_path)\n",
        "\n",
        "print(\"Size: \", len(df))\n",
        "print(\"Column names\", df.columns.tolist())\n",
        "display(df.head())\n",
        "\n",
        "# Choose a subset\n",
        "def sample_subset(df, frac=1, random_state=42):\n",
        "    return df.sample(frac=frac, random_state=random_state).reset_index(drop=True)\n",
        "\n",
        "# Set fraction to 0.1\n",
        "subset_df = sample_subset(df, frac=0.1)\n",
        "print(\"Size of subset：\", len(subset_df))\n",
        "display(subset_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76wnC3mn3zN7",
        "outputId": "e15378ee-350a-4b89-c968-e560008e93a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Subset CSV saved to: /ocean/projects/cis250079p/shared/data/msrvtt_data/MSRVTT_train.subset.csv\n"
          ]
        }
      ],
      "source": [
        "# Save the subset\n",
        "subset_path = f\"{DATA_PATH}/MSRVTT_train.subset.csv\"\n",
        "subset_df.to_csv(subset_path, index=False)\n",
        "\n",
        "print(\"Subset CSV saved to:\", subset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4reTc9BCrqJx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9E80wSjrI7z",
        "outputId": "9f98da21-8239-4eb3-c559-49e18ea7701a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current device: Tesla V100-SXM2-32GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Current device:\", torch.cuda.get_device_name() if torch.cuda.is_available() else \"CPU only\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Download CLIP-32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyebJOr2s_8n",
        "outputId": "583f52e4-9c83-4a8e-bcf4-e4277ae4fd9b"
      },
      "outputs": [],
      "source": [
        "# # Download CLIP (ViT-B/32) weight\n",
        "# !wget -P ./modules https://openaipublic.azureedge.net/clip/models/cc12fdd5df8b6c2c9118e754d5f1ec50b6706b3cd1a1e0dabfdfd5fcd8c38e38/ViT-B-32.pt\n",
        "\n",
        "# # Download CLIP (ViT-B/32) weight\n",
        "# !wget -P /ocean/projects/cis250079p/sma6/CLIP_video/modules https://openaipublic.azureedge.net/clip/models/cc12fdd5df8b6c2c9118e754d5f1ec50b6706b3cd1a1e0dabfdfd5fcd8c38e38/ViT-B-32.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "6VDrwhRKsqgm"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp8YAC93w3z7",
        "outputId": "3394a0a3-8f60-4171-fe27-9f1121fcbd55"
      },
      "outputs": [],
      "source": [
        "# # Updata changes to files. Comment if the files are not changed\n",
        "# !cd CLIP_video && git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvpQXQr8pYMj",
        "outputId": "8c3ac114-d260-4e06-c24f-20f03847c422"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# !python /ocean/projects/cis250079p/sma6/CLIP_video/main_task_retrieval.py \\\n",
        "# --do_train \\\n",
        "# --num_thread_reader=0 \\\n",
        "# --epochs=5 \\\n",
        "# --batch_size=32 \\\n",
        "# --train_csv {DATA_PATH}/MSRVTT_train.subset.csv \\\n",
        "# --val_csv {DATA_PATH}/MSRVTT_JSFUSION_test.csv \\\n",
        "# --data_path {DATA_PATH}/MSRVTT_data.json \\\n",
        "# --features_path {VIDEO_PATH} \\\n",
        "# --output_dir /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType \\\n",
        "# --lr 1e-4 \\\n",
        "# --max_words 32 \\\n",
        "# --max_frames 8 \\\n",
        "# --batch_size_val 8 \\\n",
        "# --datatype msrvtt \\\n",
        "# --expand_msrvtt_sentences \\\n",
        "# --feature_framerate 1 \\\n",
        "# --coef_lr 1e-3 \\\n",
        "# --freeze_layer_num 0 \\\n",
        "# --slice_framepos 2 \\\n",
        "# --loose_type \\\n",
        "# --linear_patch 2d \\\n",
        "# --sim_header meanP \\\n",
        "# --pretrained_clip_name ViT-B/32 \\\n",
        "# --fp16 --fp16_opt_level O1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Traceback (most recent call last):\n",
            "  File \"/ocean/projects/cis250079p/sma6/CLIP_video/main_task_retrieval.py\", line 21, in <module>\n",
            "    from dataloaders.data_dataloaders import DATALOADER_DICT\n",
            "  File \"/ocean/projects/cis250079p/sma6/CLIP_video/dataloaders/data_dataloaders.py\", line 3, in <module>\n",
            "    from dataloaders.dataloader_msrvtt_retrieval import MSRVTT_DataLoader\n",
            "  File \"/ocean/projects/cis250079p/sma6/CLIP_video/dataloaders/dataloader_msrvtt_retrieval.py\", line 13, in <module>\n",
            "    from dataloaders.rawvideo_util import RawVideoExtractor\n",
            "  File \"/ocean/projects/cis250079p/sma6/CLIP_video/dataloaders/rawvideo_util.py\", line 5, in <module>\n",
            "    from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
            "  File \"/ocean/projects/cis250079p/shared/clip_conda_env/lib/python3.10/site-packages/torchvision/__init__.py\", line 10, in <module>\n",
            "    from torchvision import _meta_registrations, datasets, io, models, ops, transforms, utils  # usort:skip\n",
            "  File \"/ocean/projects/cis250079p/shared/clip_conda_env/lib/python3.10/site-packages/torchvision/models/__init__.py\", line 2, in <module>\n",
            "    from .convnext import *\n",
            "  File \"/ocean/projects/cis250079p/shared/clip_conda_env/lib/python3.10/site-packages/torchvision/models/convnext.py\", line 8, in <module>\n",
            "    from ..ops.misc import Conv2dNormActivation, Permute\n",
            "  File \"/ocean/projects/cis250079p/shared/clip_conda_env/lib/python3.10/site-packages/torchvision/ops/__init__.py\", line 23, in <module>\n",
            "    from .poolers import MultiScaleRoIAlign\n",
            "  File \"/ocean/projects/cis250079p/shared/clip_conda_env/lib/python3.10/site-packages/torchvision/ops/poolers.py\", line 10, in <module>\n",
            "    from .roi_align import roi_align\n",
            "  File \"/ocean/projects/cis250079p/shared/clip_conda_env/lib/python3.10/site-packages/torchvision/ops/roi_align.py\", line 7, in <module>\n",
            "    from torch._dynamo.utils import is_compile_supported\n",
            "  File \"/ocean/projects/cis250079p/shared/clip_conda_env/lib/python3.10/site-packages/torch/_dynamo/__init__.py\", line 3, in <module>\n",
            "    from . import convert_frame, eval_frame, resume_execution\n",
            "  File \"/ocean/projects/cis250079p/shared/clip_conda_env/lib/python3.10/site-packages/torch/_dynamo/convert_frame.py\", line 33, in <module>\n",
            "    from torch._dynamo.symbolic_convert import TensorifyState\n",
            "  File \"<frozen importlib._bootstrap>\", line 1027, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 688, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 879, in exec_module\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 1012, in get_code\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 672, in _compile_bytecode\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "!python /ocean/projects/cis250079p/sma6/CLIP_video/main_task_retrieval.py \\\n",
        "--do_train \\\n",
        "--num_thread_reader=8 \\\n",
        "--epochs=5 \\\n",
        "--batch_size=64 \\\n",
        "--train_csv {DATA_PATH}/MSRVTT_train.subset.csv \\\n",
        "--val_csv {DATA_PATH}/MSRVTT_JSFUSION_test.csv \\\n",
        "--data_path {DATA_PATH}/MSRVTT_data.json \\\n",
        "--features_path {VIDEO_PATH} \\\n",
        "--output_dir /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType \\\n",
        "--lr 1e-4 \\\n",
        "--max_words 32 \\\n",
        "--max_frames 8 \\\n",
        "--batch_size_val 8 \\\n",
        "--datatype msrvtt \\\n",
        "--expand_msrvtt_sentences \\\n",
        "--feature_framerate 1 \\\n",
        "--coef_lr 1e-3 \\\n",
        "--freeze_layer_num 6 \\\n",
        "--slice_framepos 2 \\\n",
        "--loose_type \\\n",
        "--linear_patch 2d \\\n",
        "--sim_header meanP \\\n",
        "--pretrained_clip_name ViT-B/32 \\\n",
        "--fp16 \\\n",
        "--fp16_opt_level O1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "\n",
        "torchrun /content/CLIP4Clip/main_task_retrieval.py \\\n",
        "  --do_train \\\n",
        "  --do_pretrain \\\n",
        "  --datatype msrvtt \\\n",
        "  --data_path  \"/content/drive/MyDrive/idl_project/Data/msrvtt_data/MSRVTT_data.json\" \\\n",
        "  --train_csv  \"/content/drive/MyDrive/idl_project/Data/msrvtt_data/MSRVTT_train.9k.csv\" \\\n",
        "  --val_csv    \"/content/drive/MyDrive/idl_project/Data/msrvtt_data/MSRVTT_JSFUSION_test.csv\" \\\n",
        "  --features_path \"/content/drive/MyDrive/idl_project/Data/video\" \\\n",
        "  --output_dir \"/content/ckpts/run-4\" \\\n",
        "  --do_eval \\\n",
        "  --epochs 5 \\\n",
        "  --batch_size 16 \\\n",
        "  --batch_size_val 8 \\\n",
        "  --num_thread_reader 8 \\\n",
        "  --max_frames 8 \\\n",
        "  --max_words 32 \\\n",
        "  --loose_type \\\n",
        "  --sim_header meanP \\\n",
        "  --feature_framerate 1 \\\n",
        "  --pretrained_clip_name ViT-B/32\n",
        "  --fp16 \\\n",
        "  --fp16_opt_level O1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
