{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7_pus27iP6n",
        "outputId": "35e814d9-9f6b-4957-832e-576933fd6f28"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Thu Apr 24 14:40:09 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla V100-SXM2-32GB           On  |   00000000:3B:00.0 Off |                    0 |\n",
            "| N/A   32C    P0             41W /  300W |       1MiB /  32768MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Clone Github Repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !git clone https://github.com/sijiasiga/CLIP_video.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGfdhKIXipJr",
        "outputId": "e6795d6c-5769-4687-8c3f-a3d9ea316405"
      },
      "outputs": [],
      "source": [
        "# From CLIP\n",
        "# !conda install --yes -c pytorch pytorch=1.7.1 torchvision cudatoolkit=11.0\n",
        "# !pip install ftfy regex tqdm\n",
        "# !pip install opencv-python boto3 requests pandas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Download Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download MSRVTT training data set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WAT-NYLMm22_"
      },
      "outputs": [],
      "source": [
        "# # Comment if the file exits\n",
        "# !wget -O /ocean/projects/cis250079p/shared/data/msrvtt_data.zip https://github.com/ArrowLuo/CLIP4Clip/releases/download/v0.0/msrvtt_data.zip\n",
        "# !unzip /ocean/projects/cis250079p/shared/data/msrvtt_data.zip -d /ocean/projects/cis250079p/shared/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Download MSRVTT raw video dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !wget -O /ocean/projects/cis250079p/shared/data/msrvtt_raw_video_data.zip https://www.robots.ox.ac.uk/~maxbain/frozen-in-time/data/msrvtt_raw_video_data.zip\n",
        "# !unzip /ocean/projects/cis250079p/shared/data/msrvtt_raw_video_data.zip -d /ocean/projects/cis250079p/shared/data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### MSRVTT Data Path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "uYqhvAKVpQD9"
      },
      "outputs": [],
      "source": [
        "DATA_PATH = \"/ocean/projects/cis250079p/shared/data/msrvtt_data\"  # Directory of MSRVTT data\n",
        "VIDEO_PATH = \"/ocean/projects/cis250079p/shared/data/msrvtt_raw_video_data/videos/all/\"    # Directory of MSRVTT raw video data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Split the subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "3U2GCKmL14G6",
        "outputId": "d6116cab-8d51-4001-c050-9b300ed4d5d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size:  9000\n",
            "Column names ['video_id']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>video0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>video1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>video2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>video3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>video4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  video_id\n",
              "0   video0\n",
              "1   video1\n",
              "2   video2\n",
              "3   video3\n",
              "4   video4"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of subset： 900\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>video8405</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>video1162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>video582</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>video4081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>video9139</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    video_id\n",
              "0  video8405\n",
              "1  video1162\n",
              "2   video582\n",
              "3  video4081\n",
              "4  video9139"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load training dataset\n",
        "train_path = f\"{DATA_PATH}/MSRVTT_train.9k.csv\"\n",
        "df = pd.read_csv(train_path)\n",
        "\n",
        "print(\"Size: \", len(df))\n",
        "print(\"Column names\", df.columns.tolist())\n",
        "display(df.head())\n",
        "\n",
        "# Choose a subset\n",
        "def sample_subset(df, frac=1, random_state=42):\n",
        "    return df.sample(frac=frac, random_state=random_state).reset_index(drop=True)\n",
        "\n",
        "# Set fraction to 0.1\n",
        "subset_df = sample_subset(df, frac=0.1)\n",
        "print(\"Size of subset：\", len(subset_df))\n",
        "display(subset_df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76wnC3mn3zN7",
        "outputId": "e15378ee-350a-4b89-c968-e560008e93a2"
      },
      "outputs": [],
      "source": [
        "# # Save the subset\n",
        "# subset_path = f\"{DATA_PATH}/MSRVTT_train.subset.csv\"\n",
        "# subset_df.to_csv(subset_path, index=False)\n",
        "\n",
        "# print(\"Subset CSV saved to:\", subset_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4reTc9BCrqJx"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9E80wSjrI7z",
        "outputId": "9f98da21-8239-4eb3-c559-49e18ea7701a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current device: Tesla V100-SXM2-32GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Current device:\", torch.cuda.get_device_name() if torch.cuda.is_available() else \"CPU only\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Download CLIP-32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyebJOr2s_8n",
        "outputId": "583f52e4-9c83-4a8e-bcf4-e4277ae4fd9b"
      },
      "outputs": [],
      "source": [
        "# # Download CLIP (ViT-B/32) weight\n",
        "# !wget -P ./modules https://openaipublic.azureedge.net/clip/models/cc12fdd5df8b6c2c9118e754d5f1ec50b6706b3cd1a1e0dabfdfd5fcd8c38e38/ViT-B-32.pt\n",
        "\n",
        "# # Download CLIP (ViT-B/32) weight\n",
        "# !wget -P /ocean/projects/cis250079p/sma6/CLIP_video/modules https://openaipublic.azureedge.net/clip/models/cc12fdd5df8b6c2c9118e754d5f1ec50b6706b3cd1a1e0dabfdfd5fcd8c38e38/ViT-B-32.pt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6VDrwhRKsqgm"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fp8YAC93w3z7",
        "outputId": "3394a0a3-8f60-4171-fe27-9f1121fcbd55"
      },
      "outputs": [],
      "source": [
        "# # Updata changes to files. Comment if the files are not changed\n",
        "# !cd CLIP_video && git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bvpQXQr8pYMj",
        "outputId": "8c3ac114-d260-4e06-c24f-20f03847c422"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# !python /ocean/projects/cis250079p/sma6/CLIP_video/main_task_retrieval.py \\\n",
        "# --do_train \\\n",
        "# --num_thread_reader=0 \\\n",
        "# --epochs=5 \\\n",
        "# --batch_size=32 \\\n",
        "# --train_csv {DATA_PATH}/MSRVTT_train.subset.csv \\\n",
        "# --val_csv {DATA_PATH}/MSRVTT_JSFUSION_test.csv \\\n",
        "# --data_path {DATA_PATH}/MSRVTT_data.json \\\n",
        "# --features_path {VIDEO_PATH} \\\n",
        "# --output_dir /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType \\\n",
        "# --lr 1e-4 \\\n",
        "# --max_words 32 \\\n",
        "# --max_frames 8 \\\n",
        "# --batch_size_val 8 \\\n",
        "# --datatype msrvtt \\\n",
        "# --expand_msrvtt_sentences \\\n",
        "# --feature_framerate 1 \\\n",
        "# --coef_lr 1e-3 \\\n",
        "# --freeze_layer_num 0 \\\n",
        "# --slice_framepos 2 \\\n",
        "# --loose_type \\\n",
        "# --linear_patch 2d \\\n",
        "# --sim_header meanP \\\n",
        "# --pretrained_clip_name ViT-B/32 \\\n",
        "# --fp16 --fp16_opt_level O1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "04/24/2025 14:42:38 - INFO -   Effective parameters:\n",
            "04/24/2025 14:42:38 - INFO -     <<< batch_size: 64\n",
            "04/24/2025 14:42:38 - INFO -     <<< batch_size_val: 8\n",
            "04/24/2025 14:42:38 - INFO -     <<< cache_dir: \n",
            "04/24/2025 14:42:38 - INFO -     <<< coef_lr: 0.001\n",
            "04/24/2025 14:42:38 - INFO -     <<< cross_model: cross-base\n",
            "04/24/2025 14:42:38 - INFO -     <<< cross_num_hidden_layers: 4\n",
            "04/24/2025 14:42:38 - INFO -     <<< data_path: /ocean/projects/cis250079p/shared/data/msrvtt_data/MSRVTT_data.json\n",
            "04/24/2025 14:42:38 - INFO -     <<< datatype: msrvtt\n",
            "04/24/2025 14:42:38 - INFO -     <<< do_eval: False\n",
            "04/24/2025 14:42:38 - INFO -     <<< do_lower_case: False\n",
            "04/24/2025 14:42:38 - INFO -     <<< do_pretrain: False\n",
            "04/24/2025 14:42:38 - INFO -     <<< do_train: True\n",
            "04/24/2025 14:42:38 - INFO -     <<< epochs: 5\n",
            "04/24/2025 14:42:38 - INFO -     <<< eval_frame_order: 0\n",
            "04/24/2025 14:42:38 - INFO -     <<< expand_msrvtt_sentences: True\n",
            "04/24/2025 14:42:38 - INFO -     <<< feature_framerate: 1\n",
            "04/24/2025 14:42:38 - INFO -     <<< features_path: /ocean/projects/cis250079p/shared/data/msrvtt_raw_video_data/videos/all/\n",
            "04/24/2025 14:42:38 - INFO -     <<< fp16: True\n",
            "04/24/2025 14:42:38 - INFO -     <<< fp16_opt_level: O1\n",
            "04/24/2025 14:42:38 - INFO -     <<< freeze_layer_num: 6\n",
            "04/24/2025 14:42:38 - INFO -     <<< gradient_accumulation_steps: 1\n",
            "04/24/2025 14:42:38 - INFO -     <<< hard_negative_rate: 0.5\n",
            "04/24/2025 14:42:38 - INFO -     <<< init_model: None\n",
            "04/24/2025 14:42:38 - INFO -     <<< linear_patch: 2d\n",
            "04/24/2025 14:42:38 - INFO -     <<< loose_type: False\n",
            "04/24/2025 14:42:38 - INFO -     <<< lr: 0.0001\n",
            "04/24/2025 14:42:38 - INFO -     <<< lr_decay: 0.9\n",
            "04/24/2025 14:42:38 - INFO -     <<< margin: 0.1\n",
            "04/24/2025 14:42:38 - INFO -     <<< max_frames: 8\n",
            "04/24/2025 14:42:38 - INFO -     <<< max_words: 32\n",
            "04/24/2025 14:42:38 - INFO -     <<< n_display: 100\n",
            "04/24/2025 14:42:38 - INFO -     <<< n_gpu: 1\n",
            "04/24/2025 14:42:38 - INFO -     <<< n_pair: 1\n",
            "04/24/2025 14:42:38 - INFO -     <<< negative_weighting: 1\n",
            "04/24/2025 14:42:38 - INFO -     <<< num_thread_reader: 8\n",
            "04/24/2025 14:42:38 - INFO -     <<< output_dir: /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType\n",
            "04/24/2025 14:42:38 - INFO -     <<< pretrained_clip_name: ViT-B/32\n",
            "04/24/2025 14:42:38 - INFO -     <<< rank: 0\n",
            "04/24/2025 14:42:38 - INFO -     <<< resume_model: None\n",
            "04/24/2025 14:42:38 - INFO -     <<< sampled_use_mil: False\n",
            "04/24/2025 14:42:38 - INFO -     <<< seed: 42\n",
            "04/24/2025 14:42:38 - INFO -     <<< sim_header: tightTransf\n",
            "04/24/2025 14:42:38 - INFO -     <<< slice_framepos: 2\n",
            "04/24/2025 14:42:38 - INFO -     <<< task_type: retrieval\n",
            "04/24/2025 14:42:38 - INFO -     <<< text_num_hidden_layers: 12\n",
            "04/24/2025 14:42:38 - INFO -     <<< train_csv: /ocean/projects/cis250079p/shared/data/msrvtt_data/MSRVTT_train.subset.csv\n",
            "04/24/2025 14:42:38 - INFO -     <<< train_frame_order: 0\n",
            "04/24/2025 14:42:38 - INFO -     <<< use_mil: False\n",
            "04/24/2025 14:42:38 - INFO -     <<< val_csv: /ocean/projects/cis250079p/shared/data/msrvtt_data/MSRVTT_JSFUSION_test.csv\n",
            "04/24/2025 14:42:38 - INFO -     <<< video_dim: 1024\n",
            "04/24/2025 14:42:38 - INFO -     <<< visual_num_hidden_layers: 12\n",
            "04/24/2025 14:42:38 - INFO -     <<< warmup_proportion: 0.1\n",
            "04/24/2025 14:42:38 - INFO -     <<< world_size: 1\n",
            "04/24/2025 14:42:38 - INFO -   device: cuda n_gpu: 1\n",
            "04/24/2025 14:42:42 - INFO -   loading archive file /ocean/projects/cis250079p/sma6/CLIP_video/modules/cross-base\n",
            "04/24/2025 14:42:42 - INFO -   Model config {\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 512,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 2048,\n",
            "  \"max_position_embeddings\": 128,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 4,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 512\n",
            "}\n",
            "\n",
            "04/24/2025 14:42:42 - INFO -   Weight doesn't exsits. /ocean/projects/cis250079p/sma6/CLIP_video/modules/cross-base/cross_pytorch_model.bin\n",
            "04/24/2025 14:42:42 - WARNING -   Stage-One:True, Stage-Two:False\n",
            "04/24/2025 14:42:42 - WARNING -   \t embed_dim: 512\n",
            "04/24/2025 14:42:42 - WARNING -   \t image_resolution: 224\n",
            "04/24/2025 14:42:42 - WARNING -   \t vision_layers: 12\n",
            "04/24/2025 14:42:42 - WARNING -   \t vision_width: 768\n",
            "04/24/2025 14:42:42 - WARNING -   \t vision_patch_size: 32\n",
            "04/24/2025 14:42:42 - WARNING -   \t context_length: 77\n",
            "04/24/2025 14:42:42 - WARNING -   \t vocab_size: 49408\n",
            "04/24/2025 14:42:42 - WARNING -   \t transformer_width: 512\n",
            "04/24/2025 14:42:42 - WARNING -   \t transformer_heads: 8\n",
            "04/24/2025 14:42:42 - WARNING -   \t transformer_layers: 12\n",
            "04/24/2025 14:42:42 - WARNING -   \t\t linear_patch: 2d\n",
            "04/24/2025 14:42:42 - WARNING -   \t cut_top_layer: 0\n",
            "04/24/2025 14:42:44 - WARNING -   \t sim_header: tightTransf\n",
            "04/24/2025 14:42:44 - WARNING -   Set cross_config.num_hidden_layers: 4.\n",
            "04/24/2025 14:42:47 - INFO -   --------------------\n",
            "04/24/2025 14:42:47 - INFO -   Weights of CLIP4Clip not initialized from pretrained model: \n",
            "   cross.pooler.ln_pool.weight\n",
            "   cross.pooler.ln_pool.bias\n",
            "   cross.pooler.dense.weight\n",
            "   cross.pooler.dense.bias\n",
            "   similarity_dense.weight\n",
            "   similarity_dense.bias\n",
            "04/24/2025 14:42:47 - INFO -   Weights from pretrained model not used in CLIP4Clip: \n",
            "   clip.input_resolution\n",
            "   clip.context_length\n",
            "   clip.vocab_size\n",
            "/ocean/projects/cis250079p/shared/clip_conda_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 5, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "04/24/2025 14:42:49 - INFO -   ***** Running test *****\n",
            "04/24/2025 14:42:49 - INFO -     Num examples = 1000\n",
            "04/24/2025 14:42:49 - INFO -     Batch size = 8\n",
            "04/24/2025 14:42:49 - INFO -     Num steps = 125\n",
            "04/24/2025 14:42:49 - INFO -   ***** Running val *****\n",
            "04/24/2025 14:42:49 - INFO -     Num examples = 1000\n",
            "/ocean/projects/cis250079p/shared/clip_conda_env/lib/python3.10/site-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 5, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "04/24/2025 14:42:51 - INFO -   ***** Running training *****\n",
            "04/24/2025 14:42:51 - INFO -     Num examples = 18000\n",
            "04/24/2025 14:42:51 - INFO -     Batch size = 64\n",
            "04/24/2025 14:42:51 - INFO -     Num steps = 1405\n",
            "Epoch 1:  35%|███████▊              | 99/281 [16:46<30:54, 10.19s/it, loss=2.24]04/24/2025 14:59:38 - INFO -   Epoch: 1/5, Step: 100/281, Lr: , Loss: 2.241612, Time/step: 10.064504\n",
            "Epoch 1:  71%|██████████████▏     | 199/281 [32:01<06:04,  4.45s/it, loss=0.999]04/24/2025 15:14:53 - INFO -   Epoch: 1/5, Step: 200/281, Lr: , Loss: 0.999433, Time/step: 9.151526\n",
            "Epoch 1: 100%|████████████████████| 281/281 [44:10<00:00,  9.43s/it, loss=0.974]\n",
            "04/24/2025 15:27:02 - INFO -   Epoch 1/5 Finished, Train Loss: 2.045382\n",
            "04/24/2025 15:27:04 - INFO -   Model saved to /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.0\n",
            "04/24/2025 15:27:04 - INFO -   Optimizer saved to /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_opt.bin.0\n",
            "Evaluating: 100%|█████████████████████████████| 125/125 [02:40<00:00,  1.28s/it]0/1251/1252/1253/1254/1255/1256/1257/1258/1259/12510/12511/12512/12513/12514/12515/12516/12517/12518/12519/12520/12521/12522/12523/12524/12525/12526/12527/12528/12529/12530/12531/12532/12533/12534/12535/12536/12537/12538/12539/12540/12541/12542/12543/12545/12546/12547/12548/12549/12550/12552/12553/12554/12555/12556/12557/12558/12559/12560/12561/12562/12563/12564/12565/12566/12567/12568/12569/12570/12571/12572/12573/12574/12575/12576/12577/12578/12579/12580/12581/12582/12583/12584/12585/12586/12587/12588/12589/12590/12591/12592/12593/12594/12595/12596/12597/12598/12599/125100/125101/125102/125103/125104/125105/125106/125107/125108/125109/125110/125111/125112/125113/125114/125115/125116/125117/125118/125119/125120/125121/125122/125123/125\n",
            "04/24/2025 15:30:46 - INFO -   sim matrix size: 1000, 1000\n",
            "04/24/2025 15:30:47 - INFO -   \t Length-T: 1000, Length-V:1000\n",
            "04/24/2025 15:30:47 - INFO -   Text-to-Video:\n",
            "04/24/2025 15:30:47 - INFO -   \t>>>  R@1: 21.9 - R@5: 50.7 - R@10: 64.2 - Median R: 5.0 - Mean R: 27.5\n",
            "04/24/2025 15:30:47 - INFO -   Video-to-Text:\n",
            "04/24/2025 15:30:47 - INFO -   \t>>>  V2T$R@1: 22.6 - V2T$R@5: 51.8 - V2T$R@10: 64.9 - V2T$Median R: 5.0 - V2T$Mean R: 24.4\n",
            "04/24/2025 15:30:47 - INFO -   The best model is: /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.0, the R1 is: 21.9000\n",
            "Epoch 2:   6%|█▎                  | 18/281 [03:56<1:04:52, 14.80s/it, loss=0.54]04/24/2025 15:34:44 - INFO -   Epoch: 2/5, Step: 19/281, Lr: , Loss: 0.539615, Time/step: 2.369165\n",
            "Epoch 2:  42%|████████▊            | 118/281 [19:25<17:13,  6.34s/it, loss=0.88]04/24/2025 15:50:12 - INFO -   Epoch: 2/5, Step: 119/281, Lr: , Loss: 0.880509, Time/step: 9.285197\n",
            "Epoch 2:  78%|███████████████▌    | 218/281 [35:31<20:01, 19.08s/it, loss=0.679]04/24/2025 16:06:18 - INFO -   Epoch: 2/5, Step: 219/281, Lr: , Loss: 0.679016, Time/step: 9.659957\n",
            "Epoch 2: 100%|████████████████████| 281/281 [44:11<00:00,  9.44s/it, loss=0.829]\n",
            "04/24/2025 16:14:58 - INFO -   Epoch 2/5 Finished, Train Loss: 0.715119\n",
            "04/24/2025 16:15:00 - INFO -   Model saved to /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.1\n",
            "04/24/2025 16:15:00 - INFO -   Optimizer saved to /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_opt.bin.1\n",
            "Evaluating: 100%|█████████████████████████████| 125/125 [02:39<00:00,  1.28s/it]0/1251/1252/1253/1254/1255/1256/1257/1258/1259/12510/12511/12512/12513/12514/12515/12516/12517/12518/12519/12520/12521/12522/12523/12524/12525/12526/12527/12528/12529/12530/12531/12532/12533/12534/12535/12536/12537/12538/12539/12540/12541/12542/12543/12544/12545/12546/12547/12548/12549/12550/12551/12552/12553/12554/12555/12556/12557/12558/12559/12560/12561/12562/12563/12564/12565/12566/12567/12568/12569/12570/12571/12572/12573/12574/12575/12576/12577/12578/12579/12580/12581/12582/12583/12584/12585/12586/12587/12588/12589/12590/12591/12592/12593/12594/12595/12596/12597/12598/12599/125100/125101/125102/125103/125104/125105/125106/125107/125108/125109/125110/125111/125112/125113/125114/125115/125116/125117/125118/125119/125121/125122/125124/125\n",
            "04/24/2025 16:18:43 - INFO -   sim matrix size: 1000, 1000\n",
            "04/24/2025 16:18:43 - INFO -   \t Length-T: 1000, Length-V:1000\n",
            "04/24/2025 16:18:43 - INFO -   Text-to-Video:\n",
            "04/24/2025 16:18:43 - INFO -   \t>>>  R@1: 25.0 - R@5: 54.6 - R@10: 68.2 - Median R: 4.5 - Mean R: 27.0\n",
            "04/24/2025 16:18:43 - INFO -   Video-to-Text:\n",
            "04/24/2025 16:18:43 - INFO -   \t>>>  V2T$R@1: 28.0 - V2T$R@5: 56.5 - V2T$R@10: 67.3 - V2T$Median R: 4.0 - V2T$Mean R: 24.3\n",
            "04/24/2025 16:18:43 - INFO -   The best model is: /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.1, the R1 is: 25.0000\n",
            "Epoch 3:  13%|██▊                  | 37/281 [06:25<30:57,  7.61s/it, loss=0.658]04/24/2025 16:25:09 - INFO -   Epoch: 3/5, Step: 38/281, Lr: , Loss: 0.657566, Time/step: 3.857056\n",
            "Epoch 3:  49%|█████████▊          | 137/281 [22:47<27:27, 11.44s/it, loss=0.749]04/24/2025 16:41:31 - INFO -   Epoch: 3/5, Step: 138/281, Lr: , Loss: 0.749109, Time/step: 9.820861\n",
            "Epoch 3:  84%|████████████████▊   | 237/281 [39:15<06:53,  9.41s/it, loss=0.674]04/24/2025 16:57:58 - INFO -   Epoch: 3/5, Step: 238/281, Lr: , Loss: 0.674352, Time/step: 9.874020\n",
            "Epoch 3: 100%|████████████████████| 281/281 [45:31<00:00,  9.72s/it, loss=0.392]\n",
            "04/24/2025 17:04:15 - INFO -   Epoch 3/5 Finished, Train Loss: 0.475134\n",
            "04/24/2025 17:04:16 - INFO -   Model saved to /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2\n",
            "04/24/2025 17:04:16 - INFO -   Optimizer saved to /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_opt.bin.2\n",
            "Evaluating: 100%|█████████████████████████████| 125/125 [02:48<00:00,  1.35s/it]0/1251/1252/1253/1254/1255/1256/1257/1258/1259/12510/12511/12512/12513/12514/12515/12516/12517/12518/12519/12520/12521/12522/12523/12524/12525/12526/12527/12528/12529/12530/12531/12532/12533/12534/12535/12536/12537/12538/12539/12540/12541/12542/12543/12544/12545/12546/12547/12548/12549/12550/12551/12552/12553/12554/12555/12556/12557/12558/12559/12560/12561/12562/12563/12564/12565/12566/12567/12568/12569/12570/12571/12572/12573/12574/12575/12576/12577/12578/12579/12580/12581/12582/12583/12584/12585/12586/12587/12588/12589/12590/12591/12592/12593/12594/12595/12596/12597/12598/12599/125100/125101/125102/125103/125104/125105/125106/125107/125108/125109/125110/125111/125112/125113/125114/125115/125116/125117/125118/125119/125120/125121/125122/125124/125\n",
            "04/24/2025 17:08:35 - INFO -   sim matrix size: 1000, 1000\n",
            "04/24/2025 17:08:35 - INFO -   \t Length-T: 1000, Length-V:1000\n",
            "04/24/2025 17:08:35 - INFO -   Text-to-Video:\n",
            "04/24/2025 17:08:35 - INFO -   \t>>>  R@1: 27.6 - R@5: 54.7 - R@10: 67.7 - Median R: 4.0 - Mean R: 26.8\n",
            "04/24/2025 17:08:35 - INFO -   Video-to-Text:\n",
            "04/24/2025 17:08:35 - INFO -   \t>>>  V2T$R@1: 27.1 - V2T$R@5: 57.6 - V2T$R@10: 68.8 - V2T$Median R: 4.0 - V2T$Mean R: 26.4\n",
            "04/24/2025 17:08:35 - INFO -   The best model is: /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2, the R1 is: 27.6000\n",
            "Epoch 4:  20%|████▏                | 56/281 [10:16<18:30,  4.94s/it, loss=0.301]04/24/2025 17:18:52 - INFO -   Epoch: 4/5, Step: 57/281, Lr: , Loss: 0.300756, Time/step: 6.165148\n",
            "Epoch 4:  56%|███████████         | 156/281 [27:14<28:20, 13.60s/it, loss=0.319]04/24/2025 17:35:50 - INFO -   Epoch: 4/5, Step: 157/281, Lr: , Loss: 0.319178, Time/step: 10.179090\n",
            "Epoch 4:  91%|██████████████████▏ | 256/281 [48:36<02:15,  5.43s/it, loss=0.238]04/24/2025 17:57:12 - INFO -   Epoch: 4/5, Step: 257/281, Lr: , Loss: 0.237978, Time/step: 12.818096\n",
            "Epoch 4: 100%|████████████████████| 281/281 [51:21<00:00, 10.97s/it, loss=0.325]\n",
            "04/24/2025 17:59:57 - INFO -   Epoch 4/5 Finished, Train Loss: 0.338468\n",
            "04/24/2025 17:59:59 - INFO -   Model saved to /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.3\n",
            "04/24/2025 17:59:59 - INFO -   Optimizer saved to /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_opt.bin.3\n",
            "Evaluating: 100%|█████████████████████████████| 125/125 [02:47<00:00,  1.34s/it]0/1251/1252/1253/1254/1255/1256/1257/1258/1259/12510/12511/12512/12513/12514/12515/12516/12517/12518/12519/12520/12521/12522/12523/12524/12525/12526/12527/12528/12529/12530/12531/12532/12533/12534/12535/12536/12537/12538/12539/12540/12541/12542/12543/12544/12545/12546/12547/12548/12549/12550/12551/12552/12553/12554/12555/12556/12557/12558/12559/12560/12561/12562/12563/12564/12565/12566/12567/12568/12569/12570/12571/12572/12573/12574/12575/12576/12577/12578/12579/12580/12581/12582/12583/12584/12585/12586/12587/12588/12589/12590/12591/12592/12593/12594/12595/12596/12597/12598/12599/125100/125101/125102/125103/125104/125105/125106/125107/125108/125109/125110/125111/125112/125113/125114/125115/125116/125117/125118/125119/125120/125121/125122/125124/125\n",
            "04/24/2025 18:03:55 - INFO -   sim matrix size: 1000, 1000\n",
            "04/24/2025 18:03:55 - INFO -   \t Length-T: 1000, Length-V:1000\n",
            "04/24/2025 18:03:55 - INFO -   Text-to-Video:\n",
            "04/24/2025 18:03:55 - INFO -   \t>>>  R@1: 26.8 - R@5: 56.6 - R@10: 68.3 - Median R: 4.0 - Mean R: 29.3\n",
            "04/24/2025 18:03:55 - INFO -   Video-to-Text:\n",
            "04/24/2025 18:03:55 - INFO -   \t>>>  V2T$R@1: 27.5 - V2T$R@5: 55.3 - V2T$R@10: 67.1 - V2T$Median R: 4.0 - V2T$Mean R: 31.2\n",
            "04/24/2025 18:03:55 - INFO -   The best model is: /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2, the R1 is: 27.6000\n",
            "Epoch 5:  27%|█████▌               | 75/281 [13:33<42:04, 12.25s/it, loss=0.392]04/24/2025 18:17:29 - INFO -   Epoch: 5/5, Step: 76/281, Lr: , Loss: 0.391612, Time/step: 8.141652\n",
            "Epoch 5:  48%|█████████▋          | 136/281 [22:46<10:44,  4.45s/it, loss=0.287][ WARN:0@13897.970] global cap_ffmpeg_impl.hpp:453 _opencv_ffmpeg_interrupt_callback Stream timeout triggered after 442452.557899 ms\n",
            "\u001b[1;36m[NULL @ 0x261d2f80] \u001b[0m\u001b[1;31mInvalid NAL unit size (2531 > 1679).\n",
            "\u001b[0m\u001b[1;36m[NULL @ 0x261d2f80] \u001b[0m\u001b[1;31mmissing picture in access unit with size 1683\n",
            "\u001b[0m\u001b[0;35m[mov,mp4,m4a,3gp,3g2,mj2 @ 0x15f0e440] \u001b[0m\u001b[1;31mstream 1, offset 0x430f2: partial file\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x2ceceb80] \u001b[0m\u001b[1;31mInvalid NAL unit size (2531 > 1679).\n",
            "\u001b[0m\u001b[0;36m[h264 @ 0x2ceceb80] \u001b[0m\u001b[1;31mError splitting the input into NAL units.\n",
            "\u001b[0m\u001b[0;35m[mov,mp4,m4a,3gp,3g2,mj2 @ 0x15f0e440] \u001b[0m\u001b[1;31mstream 0, offset 0x4326d: partial file\n",
            "Epoch 5:  62%|████████████▍       | 175/281 [37:25<08:45,  4.96s/it, loss=0.374]04/24/2025 18:41:21 - INFO -   Epoch: 5/5, Step: 176/281, Lr: , Loss: 0.373955, Time/step: 14.318705\n",
            "Epoch 5:  98%|███████████████████▌| 275/281 [53:40<00:48,  8.16s/it, loss=0.291]04/24/2025 18:57:36 - INFO -   Epoch: 5/5, Step: 276/281, Lr: , Loss: 0.291099, Time/step: 9.745653\n",
            "Epoch 5: 100%|████████████████████| 281/281 [53:45<00:00, 11.48s/it, loss=0.173]\n",
            "04/24/2025 18:57:41 - INFO -   Epoch 5/5 Finished, Train Loss: 0.280821\n",
            "04/24/2025 18:57:42 - INFO -   Model saved to /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.4\n",
            "04/24/2025 18:57:42 - INFO -   Optimizer saved to /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_opt.bin.4\n",
            "Evaluating: 100%|█████████████████████████████| 125/125 [02:46<00:00,  1.33s/it]0/1251/1252/1253/1254/1255/1256/1257/1258/1259/12510/12511/12512/12513/12514/12515/12516/12517/12518/12519/12520/12521/12522/12523/12524/12525/12526/12527/12528/12529/12530/12531/12532/12533/12534/12535/12536/12537/12538/12539/12540/12541/12542/12543/12544/12545/12546/12547/12548/12549/12550/12551/12552/12553/12554/12555/12556/12557/12558/12559/12560/12561/12562/12563/12564/12565/12566/12567/12568/12569/12570/12571/12572/12573/12574/12575/12576/12577/12578/12579/12580/12581/12582/12583/12584/12585/12586/12587/12588/12589/12590/12591/12592/12593/12594/12595/12596/12597/12598/12599/125100/125101/125102/125103/125104/125105/125106/125107/125108/125109/125110/125111/125112/125113/125114/125115/125116/125117/125118/125119/125120/125121/125122/125123/125\n",
            "04/24/2025 19:01:38 - INFO -   sim matrix size: 1000, 1000\n",
            "04/24/2025 19:01:38 - INFO -   \t Length-T: 1000, Length-V:1000\n",
            "04/24/2025 19:01:38 - INFO -   Text-to-Video:\n",
            "04/24/2025 19:01:38 - INFO -   \t>>>  R@1: 26.7 - R@5: 56.5 - R@10: 68.9 - Median R: 4.0 - Mean R: 30.3\n",
            "04/24/2025 19:01:38 - INFO -   Video-to-Text:\n",
            "04/24/2025 19:01:38 - INFO -   \t>>>  V2T$R@1: 26.7 - V2T$R@5: 55.9 - V2T$R@10: 66.7 - V2T$Median R: 4.0 - V2T$Mean R: 33.4\n",
            "04/24/2025 19:01:38 - INFO -   The best model is: /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType/pytorch_model.bin.2, the R1 is: 27.6000\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "!python /ocean/projects/cis250079p/sma6/CLIP_video/main_task_retrieval.py \\\n",
        "--do_train \\\n",
        "--num_thread_reader=8 \\\n",
        "--epochs=5 \\\n",
        "--batch_size=64 \\\n",
        "--train_csv {DATA_PATH}/MSRVTT_train.subset.csv \\\n",
        "--val_csv {DATA_PATH}/MSRVTT_JSFUSION_test.csv \\\n",
        "--data_path {DATA_PATH}/MSRVTT_data.json \\\n",
        "--features_path {VIDEO_PATH} \\\n",
        "--output_dir /ocean/projects/cis250079p/sma6/CLIP_video/ckpts/ckpt_msrvtt_retrieval_looseType \\\n",
        "--lr 1e-4 \\\n",
        "--max_words 32 \\\n",
        "--max_frames 8 \\\n",
        "--batch_size_val 8 \\\n",
        "--datatype msrvtt \\\n",
        "--expand_msrvtt_sentences \\\n",
        "--feature_framerate 1 \\\n",
        "--coef_lr 1e-3 \\\n",
        "--freeze_layer_num 6 \\\n",
        "--slice_framepos 2 \\\n",
        "--loose_type \\\n",
        "--linear_patch 2d \\\n",
        "--sim_header tightTransf \\\n",
        "--pretrained_clip_name ViT-B/32 \\\n",
        "--fp16 \\\n",
        "--fp16_opt_level O1"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
